buildscript {
    repositories {
        mavenCentral()
        jcenter()
    }
}

plugins {
  id 'java'
  id 'scala'
  id 'idea'
  id 'com.github.johnrengelman.shadow' version '5.0.0'
  id "de.undercouch.download" version "3.2.0"
  id 'eclipse'
}

import com.github.jengelman.gradle.plugins.shadow.tasks.ShadowJar

repositories {
    flatDir {
        dirs 'libs'
    }
    mavenCentral()
    jcenter()
    maven { url "https://repository.cloudera.com/artifactory/cloudera-repos/" }
    maven { url "https://repo.spring.io/plugins-release/" }
}

sourceSets.main.scala.srcDir "src/main/java"
sourceSets.main.java.srcDirs = []
sourceSets.test.runtimeClasspath += files("prebuilt/lib")

sourceSets {
    main {
        resources {
            srcDirs "prebuilt/lib"
        }
    }
}

compileJava {
    options.compilerArgs << "-Xlint:all" << "-Werror" << "-XDenableSunApiLintControl" << "-Xlint:-sunapi"
}
tasks.withType(JavaCompile) {
    options.fork = true // necessary to make -XDenableSunApiLintControl work
}

project.ext {
    cachedBreezeVersion = null

    sparkVersion = System.getProperty("spark.version", "3.1.1")

    if (sparkVersion != "3.1.1") {
        project.logger.lifecycle("WARNING: Hail primarily tested with Spark 3.1.1, use other versions at your own risk.")
    }
    scalaVersion = System.getProperty("scala.version", "2.12.13")
    scalaMajorVersion = (scalaVersion =~ /^\d+.\d+/)[0]
}

compileScala {
    options.compilerArgs <<
        "-Xlint:all" <<
        "-Werror" <<
        "-XDenableSunApiLintControl" <<
        "-Xlint:-sunapi" <<
        "-Xlint:-path" // Apparently we try to find some libraries that aren't always installed

    scalaCompileOptions.additionalParameters = [
        "-target:jvm-1.8",
        "-feature",
        "-Xno-patmat-analysis",
        "-Xfatal-warnings",
        "-Xlint:_",
        "-deprecation",
        "-unchecked",
        "-Xlint:-infer-any",
        "-Xlint:-unsound-match"
    ]

    if (scalaMajorVersion == "2.12") {
        scalaCompileOptions.additionalParameters += "-Xlint:-unused"
    }

    scalaCompileOptions.forkOptions.with {
        jvmArgs = ["-Xms512M",
                   "-Xmx4096M",
                   "-Xss4M",
                   "-XX:MaxMetaspaceSize=1024M"]
    }
}

String breezeVersion() {
  if (cachedBreezeVersion == null) {
    def artifacts = configurations.justSpark.getResolvedConfiguration().getResolvedArtifacts()
    artifacts.each { ResolvedArtifact artifact ->
	def module = artifact.getModuleVersion().getId()
	if (module.getGroup() == 'org.scalanlp'
	  && module.getName() == 'breeze_' + scalaMajorVersion) {
	    cachedBreezeVersion = module.getVersion()
	}
    }
    if (cachedBreezeVersion == null) {
      throw new RuntimeException('Unable to determine breeze library version')
    }
  }
  return cachedBreezeVersion
}

configurations {
    justSpark

    all {
        resolutionStrategy {
            componentSelection {
                withModule('org.scalanlp:breeze-natives_' + scalaMajorVersion) { ComponentSelection selection ->
                    if (selection.candidate.getVersion() != breezeVersion()) {
                        selection.reject()
                    }
                }
	        }
            eachDependency { DependencyResolveDetails details ->
                if (details.requested.group == 'org.apache.spark') {
                    details.useVersion(sparkVersion)
                } else if (details.requested.group == 'org.scalanlp' && details.requested.version == '1.0') {
                    // Breeze 1.0 contains a known bug (https://github.com/scalanlp/breeze/issues/772)
                    details.useVersion('1.1')
                }
            }
	    }
    }

    compile.extendsFrom bundled, unbundled
    testCompile.extendsFrom compile, hailTest
    hailJar.extendsFrom bundled
    hailJar {
        exclude group: 'org.scala-lang', module: 'scala-library'
    }

    hailTestJar.extendsFrom hailJar, hailTest
    hailTestJar {
        exclude group: 'org.scala-lang', module: 'scala-library'
    }
}

dependencies {
    justSpark 'org.apache.spark:spark-mllib_' + scalaMajorVersion + ':' + sparkVersion

    unbundled 'org.scala-lang:scala-library:' + scalaVersion
    unbundled 'org.scala-lang:scala-reflect:' + scalaVersion

    unbundled('org.apache.spark:spark-core_' + scalaMajorVersion + ':' + sparkVersion) {
        exclude module: 'hadoop-client'
    }
    unbundled('org.apache.hadoop:hadoop-client:2.7.1') {
        exclude module: 'servlet-api'
        exclude module: 'asm'
    }
    unbundled 'org.apache.spark:spark-sql_' + scalaMajorVersion + ':' + sparkVersion
    unbundled 'org.apache.spark:spark-mllib_' + scalaMajorVersion + ':' + sparkVersion

    bundled 'org.json4s:json4s-jackson_' + scalaMajorVersion + ':3.7.0-M5'

    bundled 'org.lz4:lz4-java:1.4.0'

    // Breeze 1.0 has a known bug (https://github.com/scalanlp/breeze/issues/772)
    unbundled 'org.scalanlp:breeze-natives_' + scalaMajorVersion + ':' + breezeVersion()
    bundled('org.scalanlp:breeze-natives_' + scalaMajorVersion + ':' + breezeVersion()) {
        exclude module: 'commons-math3'
    }

    bundled 'com.github.fommil.netlib:all:1.1.2'
    bundled('com.github.samtools:htsjdk:2.21.0') {
        transitive = false
    }

    bundled group: 'org.slf4j', name: 'slf4j-api', version: '1.7.25'

    def elasticMajorVersion = System.getProperty("elasticsearch.major-version", "7")
    if (elasticMajorVersion != "7") {
        throw new UnsupportedOperationException("elasticsearch.major-version must be 7")
    }
    // This comes from a local libs directory, see Makefile
    bundled 'org.elasticsearch:elasticsearch-spark-30_2.12-8.0.0-SNAPSHOT-custom-hail-spark311'

    bundled 'com.google.cloud:google-cloud-storage:1.106.0'

    bundled 'org.apache.httpcomponents:httpcore:4.4.13'
    bundled('org.apache.httpcomponents:httpclient:4.5.12') {
        transitive = false
    }

    bundled group: 'org.ow2.asm', name: 'asm', version: '7.3.1'
    bundled group: 'org.ow2.asm', name: 'asm-util', version: '7.3.1'
    bundled group: 'org.ow2.asm', name: 'asm-analysis', version: '7.3.1'

    bundled 'net.java.dev.jna:jna:4.2.2'
    bundled('net.sourceforge.jdistlib:jdistlib:0.4.5') {
        transitive = false
    }

    hailTest 'org.testng:testng:6.8.21'
    hailTest 'org.scalatest:scalatest_' + scalaMajorVersion + ':3.0.5'

    unbundled group: 'org.apache.commons', name: 'commons-math3', version: '3.6.1'
    bundled group: 'commons-codec', name: 'commons-codec', version: '1.11'
    bundled group: 'org.apache.commons', name: 'commons-lang3', version: '3.0'

    bundled 'com.indeed:lsmtree-core:1.0.7'
    bundled 'com.indeed:util-serialization:1.0.31'
    bundled 'com.indeed:util-mmap:1.0.31'
    bundled group: 'org.freemarker', name: 'freemarker', version: '2.3.14'

    bundled 'com.kohlschutter.junixsocket:junixsocket-core:2.3.2'
}

task(checkSettings) doLast {
    def checkSeed = System.getProperty("check.seed", "1")
    if (checkSeed == "random")
        checkSeed = new Random().nextInt().toString()
    def checkSize = System.getProperty("check.size", "1000")
    def checkCount = System.getProperty("check.count", "10")

    println "check: seed = $checkSeed, size = $checkSize, count = $checkCount"

    // override with these defaults, random seed
    System.setProperty("check.seed", checkSeed)
    System.setProperty("check.size", checkSize)
    System.setProperty("check.count", checkCount)
}

test {
    useTestNG() {
        suites 'testng.xml'
    }

    // avoid stack overflow in lmmLargeExampleTest on some systems
    jvmArgs '-Xss4m', '-Xmx4096M'

    systemProperties System.getProperties()

    testLogging {
        events "passed", "skipped", "failed"
    }

    // listen to events in the test execution lifecycle
    beforeTest { descriptor ->
        logger.lifecycle("Running test: " + descriptor)
    }

    maxParallelForks((System.env.PARALLELISM == null ? "1" : System.env.PARALLELISM).toInteger())

    // make poop emoji work in generated bytecode
    systemProperty "file.encoding", "utf-8"

    testLogging {
        outputs.upToDateWhen {false}
        showStandardStreams = true
    }
}

task testServices(type: Test) {
    useTestNG() {
        suites 'testng-services.xml'
    }

    // avoid stack overflow in lmmLargeExampleTest on some systems
    jvmArgs '-Xss4m', '-Xmx4096M'

    systemProperties System.getProperties()

    testLogging {
        events "passed", "skipped", "failed"
    }

    // listen to events in the test execution lifecycle
    beforeTest { descriptor ->
        logger.lifecycle("Running test: " + descriptor)
    }

    maxParallelForks((System.env.PARALLELISM == null ? "1" : System.env.PARALLELISM).toInteger())

    // make poop emoji work in generated bytecode
    systemProperty "file.encoding", "utf-8"

    testLogging {
        outputs.upToDateWhen {false}
        showStandardStreams = true
    }
}

test.dependsOn(checkSettings)
testServices.dependsOn(checkSettings)

tasks.withType(ShadowJar) {
    manifest {
        attributes 'Implementation-Title': 'Hail',
                   'Implementation-Version': '0.0.1-SNAPSHOT'
    }
    archiveBaseName = project.name + '-all'
    mergeServiceFiles()
    zip64 true

    relocate 'org.apache.http', 'is.hail.relocated.org.apache.http'
    relocate 'com.google.common', 'is.hail.relocated.com.google.common'
    relocate 'org.objectweb', 'is.hail.relocated.org.objectweb'
    relocate 'org.codehaus.jackson', 'is.hail.relocated.org.codehaus.jackson'
    relocate 'org.apache.commons.lang3', 'is.hail.relocated.org.apache.commons.lang3'
    relocate 'org.apache.commons.io', 'is.hail.relocated.org.apache.commons.io'
    // we should really shade indeed, but it has native libraries
    // relocate 'com.indeed', 'is.hail.relocated.com.indeed'
    relocate 'com.google.cloud', 'is.hail.relocated.com.google.cloud'
    relocate 'com.github.samtools', 'is.hail.relocated.com.github.samtools'
    relocate 'org.lz4', 'is.hail.relocated.org.lz4'
    relocate 'org.freemarker', 'is.hail.relocated.org.freemarker'
    relocate 'org.json4s', 'is.hail.relocated.org.json4s'
    relocate 'com.fasterxml.jackson', 'is.hail.relocated.com.fasterxml.jackson'

    exclude 'META-INF/*.RSA'
    exclude 'META-INF/*.SF'
    exclude 'META-INF/*.DSA'
}

shadowJar {
    classifier = 'spark'
    from project.sourceSets.main.output
    configurations = [project.configurations.hailJar]
}

task shadowTestJar(type: ShadowJar) {
    classifier = 'spark-test'
    from project.sourceSets.main.output, project.sourceSets.test.output
    configurations = [project.configurations.hailTestJar]
}
