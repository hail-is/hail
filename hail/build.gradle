buildscript {
    repositories {
        mavenCentral()
    }
}

plugins {
  id 'java'
  id 'scala'
  id 'idea'
  id 'com.github.johnrengelman.shadow' version '8.1.1'
  id "de.undercouch.download" version "5.4.0"
  id 'eclipse'
}

import com.github.jengelman.gradle.plugins.shadow.tasks.ShadowJar

repositories {
    mavenCentral()
    maven { url "https://repository.cloudera.com/artifactory/cloudera-repos/" }
}

sourceSets.main.scala.srcDir "src/main/java"
sourceSets.main.java.srcDirs = []
sourceSets.test.runtimeClasspath += files("prebuilt/lib")

sourceSets {
    main {
        resources {
            srcDirs "prebuilt/lib"
        }
    }
}

compileJava {
    options.compilerArgs << "-Xlint:all" << "-Werror" << "-XDenableSunApiLintControl" << "-XDignore.symbol.file"
}
tasks.withType(JavaCompile) {
    options.fork = true // necessary to make -XDenableSunApiLintControl work
}

project.ext {
    breezeVersion = "1.1"

    sparkVersion = System.getProperty("spark.version", "3.3.0")

    if (sparkVersion != "3.3.0") {
        project.logger.lifecycle("WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk.")
    }
    scalaVersion = System.getProperty("scala.version", "2.12.15")
    scalaMajorVersion = (scalaVersion =~ /^\d+.\d+/)[0]
    assert(scalaMajorVersion == "2.12")
}

compileScala {
    options.compilerArgs <<
        "-Xlint:all" <<
        "-Werror" <<
        "-XDenableSunApiLintControl" <<
        "-XDignore.symbol.file" <<
        "-Xlint:-path" // Apparently we try to find some libraries that aren't always installed

    scalaCompileOptions.additionalParameters = [
        "-target:jvm-1.8",
        "-feature",
        "-Xno-patmat-analysis",
        "-Xfatal-warnings",
        "-Xlint:_",
        "-deprecation",
        "-unchecked",
        "-Xlint:-infer-any",
        "-Xlint:-unsound-match"
    ]

    if (scalaMajorVersion == "2.12") {
        scalaCompileOptions.additionalParameters += "-Xlint:-unused"
    }

    scalaCompileOptions.forkOptions.with {
        jvmArgs = ["-Xms512M",
                   "-Xmx4096M",
                   "-Xss4M",
                   "-XX:MaxMetaspaceSize=1024M"]
    }
}

configurations {
    all {
        resolutionStrategy {
            eachDependency { DependencyResolveDetails details ->
                if (details.requested.group == 'org.apache.spark') {
                    details.useVersion(sparkVersion)
                }
            }
	}
    }

    testImplementation.extendsFrom shadow
}

dependencies {
    shadow ('org.apache.spark:spark-mllib_' + scalaMajorVersion + ':' + sparkVersion) {
        exclude group: 'org.scalanlp'
    }

    shadow 'org.scala-lang:scala-library:' + scalaVersion
    shadow 'org.scala-lang:scala-reflect:' + scalaVersion

    shadow('org.apache.spark:spark-core_' + scalaMajorVersion + ':' + sparkVersion) {
        exclude module: 'hadoop-client'
    }
    shadow('org.apache.hadoop:hadoop-client:3.3.4') {
        exclude module: 'servlet-api'
        exclude module: 'asm'
    }
    shadow 'org.apache.spark:spark-sql_' + scalaMajorVersion + ':' + sparkVersion
    shadow 'org.apache.spark:spark-mllib_' + scalaMajorVersion + ':' + sparkVersion

    implementation('org.json4s:json4s-jackson_' + scalaMajorVersion + ':3.7.0-M11') {
        exclude group: 'com.fasterxml.jackson.core'
    }

    implementation 'org.lz4:lz4-java:1.8.0'

    // Breeze 1.0 has a known bug (https://github.com/scalanlp/breeze/issues/772)
    shadow 'org.scalanlp:breeze-natives_' + scalaMajorVersion + ':' + breezeVersion
    implementation('org.scalanlp:breeze-natives_' + scalaMajorVersion + ':' + breezeVersion) {
        exclude module: 'commons-math3'
    }
    implementation 'org.scalanlp:breeze_' + scalaMajorVersion + ':' + breezeVersion

    implementation 'com.github.fommil.netlib:all:1.1.2'
    implementation('com.github.samtools:htsjdk:3.0.5') {  // htsjdk >=4.0.0 requires Java >=17
        transitive = false
    }

    implementation group: 'org.slf4j', name: 'slf4j-api', version: '2.0.7'

    def elasticMajorVersion = System.getProperty("elasticsearch.major-version", "7")
    if (elasticMajorVersion != "7" && elasticMajorVersion != "8") {
        throw new UnsupportedOperationException("elasticsearch.major-version must be 7 or 8")
    }

    if (sparkVersion.startsWith("3.")) {
        if (elasticMajorVersion == "8") {
            implementation 'org.elasticsearch:elasticsearch-spark-30_2.12:8.4.3'
        }
        else if (elasticMajorVersion == "7") {
            implementation 'org.elasticsearch:elasticsearch-spark-30_2.12:8.4.3'
        }
    }
    else if (sparkVersion.startsWith("2.4.")) {
        assert(elasticMajorVersion == "7")
        implementation 'org.elasticsearch:elasticsearch-spark-20_2.12:8.6.1'
    }
    else {
        throw new UnsupportedOperationException("Couldn't pick a valid elasticsearch.")
    }

    implementation(group: 'com.google.cloud', name: 'google-cloud-storage', version: '2.27.1') {
        exclude group: 'com.fasterxml.jackson.core'
    }

    implementation 'org.apache.httpcomponents:httpcore:4.4.14'
    implementation('org.apache.httpcomponents:httpclient:4.5.13') {
        transitive = false
    }

    implementation group: 'org.ow2.asm', name: 'asm', version: '7.3.1'
    implementation group: 'org.ow2.asm', name: 'asm-util', version: '9.6'
    implementation group: 'org.ow2.asm', name: 'asm-analysis', version: '7.3.1'

    implementation 'net.java.dev.jna:jna:5.13.0'
    implementation('net.sourceforge.jdistlib:jdistlib:0.4.5') {
        transitive = false
    }

    testImplementation 'org.testng:testng:6.8.21'
    testImplementation 'org.scalatest:scalatest_' + scalaMajorVersion + ':3.0.5'

    shadow group: 'org.apache.commons', name: 'commons-math3', version: '3.6.1'
    implementation group: 'commons-codec', name: 'commons-codec', version: '1.15'
    implementation group: 'org.apache.commons', name: 'commons-lang3', version: '3.12.0'
    implementation(group: 'org.apache.avro', name: 'avro', version: '1.11.2') {
        exclude group: 'com.fasterxml.jackson.core'
    }

    implementation 'commons-io:commons-io:2.11.0'

    implementation group: 'org.freemarker', name: 'freemarker', version: '2.3.31'

    implementation 'com.kohlschutter.junixsocket:junixsocket-core:2.6.1'

    implementation 'com.github.luben:zstd-jni:1.5.5-2'

    implementation project(path: ':shadedazure', configuration: 'shadow')
}

task(checkSettings) doLast {
    def checkSeed = System.getProperty("check.seed", "1")
    if (checkSeed == "random")
        checkSeed = new Random().nextInt().toString()
    def checkSize = System.getProperty("check.size", "1000")
    def checkCount = System.getProperty("check.count", "10")

    println "check: seed = $checkSeed, size = $checkSize, count = $checkCount"

    // override with these defaults, random seed
    System.setProperty("check.seed", checkSeed)
    System.setProperty("check.size", checkSize)
    System.setProperty("check.count", checkCount)
}

test {
    useTestNG() {
        suites 'testng.xml'
    }

    // avoid stack overflow in lmmLargeExampleTest on some systems
    jvmArgs '-Xss4m', '-Xmx4096M'

    systemProperties System.getProperties()

    testLogging {
        events "passed", "skipped", "failed"
    }

    // listen to events in the test execution lifecycle
    beforeTest { descriptor ->
        logger.lifecycle("Running test: " + descriptor)
    }

    maxParallelForks((System.env.PARALLELISM == null ? "1" : System.env.PARALLELISM).toInteger())

    // make poop emoji work in generated bytecode
    systemProperty "file.encoding", "utf-8"

    testLogging {
        outputs.upToDateWhen {false}
        showStandardStreams = true
    }
}

task testServices(type: Test) {
    useTestNG() {
        suites 'testng-services.xml'
    }

    // avoid stack overflow in lmmLargeExampleTest on some systems
    jvmArgs '-Xss4m', '-Xmx4096M'

    systemProperties System.getProperties()

    testLogging {
        events "passed", "skipped", "failed"
    }

    // listen to events in the test execution lifecycle
    beforeTest { descriptor ->
        logger.lifecycle("Running test: " + descriptor)
    }

    maxParallelForks((System.env.PARALLELISM == null ? "1" : System.env.PARALLELISM).toInteger())

    // make poop emoji work in generated bytecode
    systemProperty "file.encoding", "utf-8"

    testLogging {
        outputs.upToDateWhen {false}
        showStandardStreams = true
    }
}

task testFS(type: Test) {
    useTestNG() {
        suites 'testng-fs.xml'
    }

    testLogging {
        events "passed", "skipped", "failed"
    }

    // listen to events in the test execution lifecycle
    beforeTest { descriptor ->
        logger.lifecycle("Running test: " + descriptor)
    }

    maxParallelForks((System.env.PARALLELISM == null ? "1" : System.env.PARALLELISM).toInteger())

    testLogging {
        outputs.upToDateWhen {false}
        showStandardStreams = true
    }
}

test.dependsOn(checkSettings)
testServices.dependsOn(checkSettings)
testFS.dependsOn(checkSettings)

tasks.withType(ShadowJar) {
    manifest {
        attributes 'Implementation-Title': 'Hail',
                   'Implementation-Version': '0.0.1-SNAPSHOT'
    }
    archiveBaseName = project.name + '-all'
    mergeServiceFiles()
    zip64 true

    relocate 'org.apache.http', 'is.hail.relocated.org.apache.http'
    relocate 'com.google.common', 'is.hail.relocated.com.google.common'
    relocate 'org.objectweb', 'is.hail.relocated.org.objectweb'
    relocate 'org.codehaus.jackson', 'is.hail.relocated.org.codehaus.jackson'
    relocate 'org.codehaus.stax2', 'org.apache.hadoop.shaded.org.codehaus.stax2'
    relocate 'org.apache.commons.lang3', 'is.hail.relocated.org.apache.commons.lang3'
    relocate 'org.apache.commons.io', 'is.hail.relocated.org.apache.commons.io'
    relocate 'com.google.cloud', 'is.hail.relocated.com.google.cloud'
    relocate 'com.github.samtools', 'is.hail.relocated.com.github.samtools'
    relocate 'org.lz4', 'is.hail.relocated.org.lz4'
    relocate 'org.freemarker', 'is.hail.relocated.org.freemarker'
    relocate 'org.json4s', 'is.hail.relocated.org.json4s'
    relocate 'org.elasticsearch', 'is.hail.relocated.org.elasticsearch'

    // Breeze 1.0 is broken, it is never ok to use Breeze 1.0 or earlier.
    relocate 'breeze', 'is.hail.relocated.breeze'

    exclude 'META-INF/*.RSA'
    exclude 'META-INF/*.SF'
    exclude 'META-INF/*.DSA'
}

shadowJar {
    archiveClassifier = 'spark'
}

task shadowTestJar(type: ShadowJar) {
    archiveClassifier = 'spark-test'
    from sourceSets.test.output
    from sourceSets.main.output
    configurations = [project.configurations.testRuntimeClasspath]
}

task printClasspath(type: Exec) {
    commandLine = ['echo', "${sourceSets.main.runtimeClasspath.asPath}"]
}
