FROM {{ hail_ubuntu_image.image }}

RUN hail-apt-get-install \
    git \
    htop \
    unzip bzip2 zip tar \
    rsync \
    emacs-nox \
    xsltproc pandoc \
    openjdk-8-jdk-headless \
    liblapack3 \
    liblz4-dev \
    g++-10 \
    gcc-10 \
    cmake \
    && \
    update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-10 10 && \
    update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-10 10

RUN hail-apt-get-install maven

RUN mkdir -p plink && \
  cd plink && \
  curl >plink_linux_x86_64.zip https://storage.googleapis.com/hail-common/plink_linux_x86_64_20181202.zip && \
  unzip plink_linux_x86_64.zip && \
  mv plink /usr/local/bin && \
  cd .. && \
  rm -rf plink

COPY hail/python/pinned-requirements.txt requirements.txt
COPY hail/python/dev/pinned-requirements.txt dev-requirements.txt
RUN hail-pip-install -r requirements.txt -r dev-requirements.txt

ENV SPARK_HOME /usr/local/lib/python3.8/dist-packages/pyspark
ENV PATH "$PATH:$SPARK_HOME/sbin:$SPARK_HOME/bin"
ENV PYSPARK_PYTHON python3
ENV PYSPARK_SUBMIT_ARGS "--conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator pyspark-shell"

RUN curl >${SPARK_HOME}/jars/gcs-connector-hadoop2-2.2.7.jar https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-hadoop2-2.2.7.jar
COPY docker/core-site.xml ${SPARK_HOME}/conf/core-site.xml

COPY /wheel-container.tar /wheel-container.tar
RUN mkdir /__hail && \
    cd /__hail && \
    tar xvf /wheel-container.tar && \
    python3 -m pip install --no-dependencies hail-*-py3-none-any.whl && \
    rm -rf /wheel-container.tar && \
    rm -rf /__hail
