{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores variability in hail's python (macro)-benchmarks when\n",
    "said benchmarks are executed on the hail batch service. The analyses within \n",
    "are based off the methods proposed in [1], albeit slightly modified for long\n",
    "running benchmarks. The goals of these analyses are\n",
    "\n",
    "- to determine if we can detect slowdowns of 5% or less reliably when running\n",
    "  benchmarks on hail batch.\n",
    "- to identify configurations (number of batch jobs x iterations) that allow us\n",
    "  to detect slowdowns efficiently (ie without excesssive time and money).\n",
    "\n",
    "[1] Laaber et al., Software Microbenchmarking in the Cloud.How Bad is it Really?\n",
    "    https://dl.acm.org/doi/10.1007/s10664-019-09681-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import plotly.io as pio\n",
    "import yaml\n",
    "from benchmark.tools import annotate_index, maybe\n",
    "from benchmark.tools.impex import import_benchmarks\n",
    "from benchmark.tools.plotting import (\n",
    "    plot_iteration_against_time,\n",
    "    plot_mean_time_per_instance,\n",
    ")\n",
    "from benchmark.tools.statistics import (\n",
    "    bootstrap_mean_confidence_interval,\n",
    "    laaber_mds,\n",
    "    schultz_mds,\n",
    "    variability,\n",
    ")\n",
    "from IPython.display import Pretty, clear_output, display\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "import hail as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = str(Path().absolute())\n",
    "hl.init(backend='spark', quiet=True)\n",
    "\n",
    "init_notebook_mode()\n",
    "pio.renderers.default = 'notebook_connected'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import benchmark data\n",
    "\n",
    "Benchmarks under `hail/python/benchmarks` are executed with a custom\n",
    "pytest plugin and their results are output as json lines (.jsonl).\n",
    "\n",
    "Unscrupulously, we use hail to analyse itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hl.TemporaryDirectory() as tmpdir:\n",
    "    ht = import_benchmarks(Path(f'{prefix}/in/benchmarks.jsonl'), tmpdir=tmpdir)\n",
    "    ht = ht.checkpoint(f\"{prefix}/out/benchmarks.ht\")\n",
    "\n",
    "benchmarks = ht.aggregate(hl.agg.collect_as_set(ht.path + hl.str('::') + ht.name))\n",
    "benchmarks = sorted(benchmarks)\n",
    "print(*benchmarks, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next section, we'll estimate the number of iterations required for\n",
    "a benchmark to reach a steady-state, or the number of so-called \"burn-in\"\n",
    "iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_stable_index = {\n",
    "    'test_analyze_benchmarks': 5,\n",
    "    'test_block_matrix_to_matrix_table_row_major': 4,\n",
    "    'test_blockmatrix_write_from_entry_expr_range_mt_standardize': 8,\n",
    "    'test_blockmatrix_write_from_entry_expr_range_mt': 10,\n",
    "    'test_concordance': 2,\n",
    "    'test_export_range_matrix_table_col_p100': 15,\n",
    "    'test_export_range_matrix_table_entry_field_p100': 3,\n",
    "    'test_export_range_matrix_table_row_p100': 8,\n",
    "    'test_export_vcf': 8,\n",
    "    'test_genetics_pipeline': 4,\n",
    "    'test_gnomad_coverage_stats_optimized': 5,\n",
    "    'test_gnomad_coverage_stats': 5,\n",
    "    'test_group_by_collect_per_row': 5,\n",
    "    'test_group_by_take_rekey': 10,\n",
    "    'test_hwe_normalized_pca_blanczos_small_data_0_iterations': 8,\n",
    "    'test_hwe_normalized_pca_blanczos_small_data_10_iterations': 8,\n",
    "    'test_hwe_normalized_pca': 6,\n",
    "    'test_import_and_transform_gvcf': 2,\n",
    "    'test_import_bgen_filter_count': 18,\n",
    "    'test_import_bgen_force_count_all': 4,\n",
    "    'test_import_bgen_force_count_just_gp': 20,\n",
    "    'test_import_bgen_info_score': 12,\n",
    "    'test_import_gvcf_force_count': 2,\n",
    "    'test_import_vcf_count_rows': 1,\n",
    "    'test_import_vcf_write': 5,\n",
    "    'test_join_partitions_table[10-10]': 4,\n",
    "    'test_join_partitions_table[10-100]': 2,\n",
    "    'test_join_partitions_table[10-1000]': 5,\n",
    "    'test_join_partitions_table[100-10]': 10,\n",
    "    'test_join_partitions_table[100-100]': 10,\n",
    "    'test_join_partitions_table[100-1000]': 8,\n",
    "    'test_join_partitions_table[1000-10]': 12,\n",
    "    'test_join_partitions_table[1000-100]': 10,\n",
    "    'test_join_partitions_table[1000-1000]': 8,\n",
    "    'test_kyle_sex_specific_qc': 6,\n",
    "    'test_large_range_matrix_table_sum': 5,\n",
    "    'test_ld_prune_profile_25': 10,\n",
    "    'test_linear_regression_rows': 10,\n",
    "    'test_logistic_regression_rows_wald': 5,\n",
    "    'test_make_ndarray': 5,\n",
    "    'test_matrix_table_aggregate_entries': 8,\n",
    "    'test_matrix_table_array_arithmetic': 20,\n",
    "    'test_matrix_table_call_stats_star_star': 8,\n",
    "    'test_matrix_table_cols_show': 5,\n",
    "    'test_matrix_table_decode_and_count_just_gt': 5,\n",
    "    'test_matrix_table_decode_and_count': 8,\n",
    "    'test_matrix_table_entries_show': 4,\n",
    "    'test_matrix_table_entries_table_no_key': 4,\n",
    "    'test_matrix_table_entries_table': 10,\n",
    "    'test_matrix_table_filter_entries_unfilter': 8,\n",
    "    'test_matrix_table_filter_entries': 6,\n",
    "    'test_matrix_table_many_aggs_col_wise': 3,\n",
    "    'test_matrix_table_many_aggs_row_wise': 2,\n",
    "    'test_matrix_table_nested_annotate_rows_annotate_entries': 4,\n",
    "    'test_matrix_table_rows_force_count': 20,\n",
    "    'test_matrix_table_rows_is_transition': 5,\n",
    "    'test_matrix_table_rows_show': 10,\n",
    "    'test_matrix_table_scan_count_cols_2': 20,\n",
    "    'test_matrix_table_scan_count_rows_2': 5,\n",
    "    'test_matrix_table_show': 7,\n",
    "    'test_matrix_table_take_col': 10,\n",
    "    'test_matrix_table_take_entry': 8,\n",
    "    'test_matrix_table_take_row': 10,\n",
    "    'test_minimal_detectable_slowdown[laaber_mds]': 5,\n",
    "    'test_minimal_detectable_slowdown[schultz_mds]': 6,\n",
    "    'test_mt_group_by_memory_usage': 5,\n",
    "    'test_mt_localize_and_collect': 5,\n",
    "    'test_ndarray_addition': 10,\n",
    "    'test_ndarray_matmul_float64': 6,\n",
    "    'test_ndarray_matmul_int64': 10,\n",
    "    'test_pc_relate_5k_5k': 4,\n",
    "    'test_pc_relate': 3,\n",
    "    'test_per_row_stats_star_star': 10,\n",
    "    'test_python_only_10k_combine': 6,\n",
    "    'test_python_only_10k_transform': 10,\n",
    "    'test_read_decode_gnomad_coverage': 10,\n",
    "    'test_read_force_count_partitions[10]': 10,\n",
    "    'test_read_force_count_partitions[100]': 8,\n",
    "    'test_read_force_count_partitions[1000]': 10,\n",
    "    'test_read_with_index[1000]': 8,\n",
    "    'test_sample_qc': 3,\n",
    "    'test_sentinel_cpu_hash_1': 5,\n",
    "    'test_sentinel_read_gunzip': 10,\n",
    "    'test_shuffle_key_by_aggregate_bad_locality': 8,\n",
    "    'test_shuffle_key_by_aggregate_good_locality': 5,\n",
    "    'test_shuffle_key_rows_by_4096_byte_rows': 2,\n",
    "    'test_shuffle_key_rows_by_65k_byte_rows': 4,\n",
    "    'test_shuffle_key_rows_by_mt': 10,\n",
    "    'test_shuffle_order_by_10m_int': 10,\n",
    "    'test_split_multi_hts': 10,\n",
    "    'test_split_multi': 8,\n",
    "    'test_sum_table_of_ndarrays': 5,\n",
    "    'test_table_aggregate_approx_cdf': 4,\n",
    "    'test_table_aggregate_array_sum': 5,\n",
    "    'test_table_aggregate_counter': 10,\n",
    "    'test_table_aggregate_downsample_dense': 5,\n",
    "    'test_table_aggregate_downsample_worst_case': 10,\n",
    "    'test_table_aggregate_int_stats': 5,\n",
    "    'test_table_aggregate_linreg': 8,\n",
    "    'test_table_aggregate_take_by_strings': 10,\n",
    "    'test_table_annotate_many_flat': 5,\n",
    "    'test_table_big_aggregate_compilation': 4,\n",
    "    'test_table_big_aggregate_compile_and_execute': 2,\n",
    "    'test_table_expr_take': 25,\n",
    "    'test_table_foreign_key_join[1000000-1000]': 3,\n",
    "    'test_table_foreign_key_join[1000000-1000000]': 3,\n",
    "    'test_table_group_by_aggregate_sorted': 8,\n",
    "    'test_table_group_by_aggregate_unsorted': 7,\n",
    "    'test_table_import_ints_impute': 8,\n",
    "    'test_table_import_ints': 4,\n",
    "    'test_table_import_strings': 3,\n",
    "    'test_table_key_by_shuffle': 3,\n",
    "    'test_table_python_construction': 10,\n",
    "    'test_table_range_array_range_force_count': 6,\n",
    "    'test_table_range_force_count': 10,\n",
    "    'test_table_range_join[1000000000-1000]': 20,\n",
    "    'test_table_range_join[1000000000-1000000000]': 10,\n",
    "    'test_table_range_means': 10,\n",
    "    'test_table_read_force_count_ints': 5,\n",
    "    'test_table_read_force_count_strings': 4,\n",
    "    'test_table_scan_prev_non_null': 20,\n",
    "    'test_table_scan_sum_1k_partitions': 2,\n",
    "    'test_table_show': 12,\n",
    "    'test_table_take': 20,\n",
    "    'test_test_head_and_tail_region_memory': 10,\n",
    "    'test_test_inner_join_region_memory': 10,\n",
    "    'test_test_left_join_region_memory': 10,\n",
    "    'test_test_map_filter_region_memory': 10,\n",
    "    'test_union_partitions_table[10-10]': 4,\n",
    "    'test_union_partitions_table[10-100]': 5,\n",
    "    'test_union_partitions_table[10-1000]': 8,\n",
    "    'test_union_partitions_table[100-10]': 16,\n",
    "    'test_union_partitions_table[100-100]': 5,\n",
    "    'test_union_partitions_table[100-1000]': 15,\n",
    "    'test_union_partitions_table[1000-10]': 10,\n",
    "    'test_union_partitions_table[1000-100]': 6,\n",
    "    'test_union_partitions_table[1000-1000]': 15,\n",
    "    'test_variant_and_sample_qc_nested_with_filters_2': 2,\n",
    "    'test_variant_and_sample_qc_nested_with_filters_4_counts': 8,\n",
    "    'test_variant_and_sample_qc_nested_with_filters_4': 10,\n",
    "    'test_variant_and_sample_qc': 10,\n",
    "    'test_variant_qc': 5,\n",
    "    'test_vds_combiner_chr22': 10,\n",
    "    'test_write_profile_mt': 8,\n",
    "    'test_write_range_matrix_table_p100': 2,\n",
    "    'test_write_range_table[10000000-10]': 3,\n",
    "    'test_write_range_table[10000000-100]': 3,\n",
    "    'test_write_range_table[10000000-1000]': 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short of an accurate algorithm for computing this, you, noble reader, are\n",
    "tasked with the mind-numbing task of looking at graphs and picking numbers.\n",
    "This is an iterative process and you'll likely lose the will to live mid-way.\n",
    "\n",
    "Persevere, friend. Your sacrifice will not go unrewarded.\n",
    "\n",
    "In what follows, you'll be shown two plots. On the top will be the unfiltered\n",
    "benchmark times vs iteration for all batch jobs. The plot below will show the\n",
    "same benchmark filtered to the number of burn in iterations you selected\n",
    "previously.\n",
    "\n",
    "You'll be prompted to enter a new first stable index for each benchmark until\n",
    "you arrive at a fixed point. Note that some benchmarks never really reach\n",
    "stability. In this case try to pick a value that compromises between cost and\n",
    "accuracy (ie if a benchmark is really slow, we don't want to be doing tons\n",
    "of burn in iterations, whereas for a fast benchmark we could justify more).\n",
    "\n",
    "Good luck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = hl.read_table(f'{prefix}/out/benchmarks.ht')\n",
    "names: List[str] = ht.aggregate(hl.agg.collect_as_set(ht.name))  # type: ignore\n",
    "names = sorted(names)\n",
    "\n",
    "while len(names) != 0:\n",
    "    __new_names, names = names, []\n",
    "    for fig in plot_iteration_against_time(ht, __new_names, first_stable_index):\n",
    "        clear_output(wait=True)\n",
    "        pio.renderers.default = 'notebook'\n",
    "\n",
    "        name: str = fig.labels.title  # type: ignore\n",
    "        cur_index = first_stable_index.get(name)\n",
    "\n",
    "        try:\n",
    "            fig.show()\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            new_index = maybe(int, input('Enter the first stable index (or blank keep same)') or None)\n",
    "            if new_index is not None and new_index != cur_index:\n",
    "                first_stable_index[name] = new_index\n",
    "                names.append(name)\n",
    "        except KeyboardInterrupt as _:\n",
    "            break\n",
    "\n",
    "first_stable_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step of cleaning, we'll filter out iterations that differ by some\n",
    "multiplier of the median for each instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_burn_in_iterations(ht: hl.Table, first_stable_index: Dict[str, int]) -> hl.Table:\n",
    "    ht = ht.annotate_globals(first_stable_index=first_stable_index)\n",
    "    return ht.select(\n",
    "        instances=ht.instances.map(\n",
    "            lambda instance: instance.annotate(\n",
    "                iterations=hl.filter(\n",
    "                    lambda t: t.idx >= ht.first_stable_index.get(ht.name, 0),\n",
    "                    annotate_index(instance.iterations),\n",
    "                ),\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_outliers(ht: hl.Table, factor: hl.Float64Expression) -> hl.Table:\n",
    "    return ht.select(\n",
    "        instances=ht.instances.map(\n",
    "            lambda instance: instance.annotate(\n",
    "                trials=hl.bind(\n",
    "                    lambda median: instance.iterations.filter(\n",
    "                        lambda t: hl.max([t.time, median]) / hl.min([t.time, median]) < factor\n",
    "                    ),\n",
    "                    hl.median(instance.iterations.map(lambda t: t.time)),\n",
    "                )\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_names(ht: hl.Table, names: hl.SetExpression) -> hl.Table:\n",
    "    return ht.filter(names.contains(ht.name))\n",
    "\n",
    "\n",
    "def filter_failed_iterations(ht: hl.Table) -> hl.Table:\n",
    "    return ht.annotate(\n",
    "        instances=ht.instances.map(\n",
    "            lambda i: i.annotate(\n",
    "                iterations=hl.filter(\n",
    "                    lambda t: ~t.timed_out | hl.is_missing(t.failure),\n",
    "                    i.iterations,\n",
    "                ),\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_non_viable_instances(\n",
    "    ht: hl.Table,\n",
    "    ninstances: hl.Int32Expression,\n",
    "    niterations: hl.Int32Expression,\n",
    ") -> hl.Table:\n",
    "    ht = ht.annotate(\n",
    "        instances=hl.filter(\n",
    "            lambda instance: hl.len(instance.iterations) >= niterations,\n",
    "            ht.instances,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return ht.filter(hl.len(ht.instances) >= ninstances)\n",
    "\n",
    "\n",
    "ht = hl.read_table(f'{prefix}/out/benchmarks.ht')\n",
    "all: List[str] = ht.aggregate(hl.agg.collect_as_set(ht.name))  # type: ignore\n",
    "\n",
    "ht = filter_names(ht, hl.set([n for n in all if n in first_stable_index]))\n",
    "ht = filter_burn_in_iterations(ht, first_stable_index)\n",
    "ht = filter_failed_iterations(ht)\n",
    "ht = filter_outliers(ht, hl.float64(10))\n",
    "ht = filter_non_viable_instances(ht, hl.int(50), hl.int(50))\n",
    "ht = ht.checkpoint(f'{prefix}/out/filtered.ht', overwrite=True)\n",
    "\n",
    "benchmarks = ht.aggregate(hl.agg.collect_as_set(ht.name))\n",
    "\n",
    "print('Filtered:', *(n for n in all if n not in set(benchmarks)), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These plots show the mean time per instance. This provides a visual way of\n",
    "# identifying differences in instance type if there are multiple distinct layers\n",
    "\n",
    "ht = hl.read_table(f'{prefix}/out/filtered.ht')\n",
    "for f in plot_mean_time_per_instance(ht):\n",
    "    f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laaber et al. section 4\n",
    "ht = hl.read_table(f'{prefix}/out/filtered.ht')\n",
    "ht = ht.select(instances=ht.instances.iterations.time)\n",
    "ht.select(variability=variability(ht)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laaber et al. section 5 - boostrapping confidence intervals of the mean\n",
    "\n",
    "bootstrap_mean_confidence_interval(ht, 1000, 0.95).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, use QoB for the next section\n",
    "hl.stop()\n",
    "hl.init(backend='batch')\n",
    "\n",
    "new_prefix = hl.current_backend().remote_tmpdir\n",
    "hl.current_backend().fs.copy(f'{prefix}/out/filtered.ht', f'{new_prefix}/out/filtered.ht')\n",
    "prefix, new_prefix = new_prefix, prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laaber et al - Minimal-Detectable Slowdown\n",
    "\n",
    "ht = hl.read_table(f'{prefix}/out/filtered.ht')\n",
    "ht = ht.select(instances=ht.instances.iterations.time)\n",
    "\n",
    "laaber_mds(ht).write(f'{prefix}/out/laaber-mds.ht')\n",
    "schultz_mds(ht).write(f'{prefix}/out/schultz-mds.ht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch back to local spark for plotting\n",
    "for mds in ['laaber', 'schultz']:\n",
    "    hl.current_backend().fs.copy(f'{prefix}/out/{mds}-mds.ht-2', f'{new_prefix}/out/{mds}-mds.ht-2')\n",
    "\n",
    "prefix, new_prefix = new_prefix, prefix\n",
    "hl.stop()\n",
    "hl.init(backend='spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "t = hl.read_table(f'{prefix}/out/filtered.ht')\n",
    "t = t.select(instances=t.instances.iterations.time)\n",
    "t = t.select(\n",
    "    mean=t.instances.aggregate(lambda k: hl.agg.explode(hl.agg.mean, k)),\n",
    "    cv=variability(t).total,\n",
    ")\n",
    "benchmarks = t.aggregate(hl.agg.collect((t.path, t.name, t.mean, t.cv)))\n",
    "\n",
    "laaber, schultz = [\n",
    "    (\n",
    "        t := hl.read_table(f'{prefix}/out/{m}-mds.ht'),\n",
    "        t := t._key_by_assert_sorted('path', 'name', 'slowdown', 'ninstances', 'niterations'),\n",
    "        t.select('ibs', 'tbs'),\n",
    "    )[-1]\n",
    "    for m in ('laaber', 'schultz')\n",
    "]\n",
    "\n",
    "mds = laaber.select(laaber=laaber.row_value, schultz=schultz[laaber.key])\n",
    "\n",
    "for path, name, rt, cv in benchmarks:\n",
    "    info = Pretty(\n",
    "        yaml.dump(\n",
    "            data=[\n",
    "                {\n",
    "                    'item': f'{path}::{name}',\n",
    "                    'burn_in': first_stable_index[name],\n",
    "                    'mean': float(f'{rt:.3f}'),\n",
    "                    'cv': float(f'{cv:.3f}'),\n",
    "                    'config': [],\n",
    "                }\n",
    "            ],\n",
    "            sort_keys=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    display(info, clear=True)\n",
    "\n",
    "    t = mds.filter((mds.path == path) & (mds.name == name))\n",
    "    t.filter(t.slowdown == 1).show(100_000)\n",
    "\n",
    "    try:\n",
    "        config = input('Enter `ninstances, niterations` that minimises the likelihood of detecting a false positive.')\n",
    "\n",
    "        if not config:\n",
    "            continue\n",
    "\n",
    "        display(info, clear=True)\n",
    "\n",
    "        # Now identify a configuration of instances, iterations and burn-in iterations\n",
    "        m, n = [int(x.strip()) for x in config.split(',')]\n",
    "        t.filter((t.slowdown > 1) & (hl.tuple([t.ninstances, t.niterations]) >= (m, n))).show(100_000)\n",
    "\n",
    "        input()\n",
    "    except KeyboardInterrupt as _:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
