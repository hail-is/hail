from dataclasses import dataclass, field
import json
from typing import Dict, List, Optional, Union

from hailtop.aiotools.fs import AsyncFS
import hailtop.batch as hb

from .config import CheckpointConfigMixin, JobConfigMixin
from .constants import SaigeAnalysisType, SaigeInputDataType
from .io import (
    HailTableResourceFile,
    PlinkResourceGroup,
    SaigeGeneGLMMResourceGroup,
    SaigeGLMMResourceGroup,
    SaigeSparseGRMResourceGroup,
    SaigeGeneResultResourceGroup,
    SaigeResultResourceGroup,
    TextResourceFile,
    checkpoint_if_requested,
    load_saige_glmm_file,
    load_saige_result_file,
    load_saige_sparse_grm_file,
    load_text_file,
    new_hail_table,
    new_saige_glmm_file,
    new_saige_result_file,
    new_saige_sparse_grm_file,
    new_text_file,
)
from .phenotype import Phenotype, PhenotypeConfig, SaigePhenotype, saige_phenotype_to_test_type
from .variant_chunk import VariantChunk


def get_output_dir(config: CheckpointConfigMixin, temp_dir: str, checkpoint_dir: Optional[str]) -> str:
    if config.use_checkpoints or config.checkpoint_output:
        if checkpoint_dir is None:
            raise ValueError('must specify a checkpoint directory to use checkpoints and/or checkpoint output')
        return checkpoint_dir
    return temp_dir


def bool_upper_str(val: bool) -> str:
    return str(val).upper()


@dataclass
class SparseGRMStep(CheckpointConfigMixin, JobConfigMixin):
    """Step for computing the Sparse GRM in a SAIGE pipeline.

    Configures a Hail Batch job to run the SAIGE binary ``createSparseGRM.R``.

    This class is used as an input to SaigeConfig in order to specify
    how the Sparse GRM step is executed in SAIGE.

    Examples
    --------

    Use 16 cores when running the sparse GRM step:

    >>> sparse_grm_step = SparseGRMStep(cpu=16)

    Set the relatedness cutoff to 0.05:

    >>> sparse_grm_step = SparseGRMStep(relatedness_cutoff=0.05)

    Notes
    -----

    You can also create a subclass of this class and redefine the
    job name, job attributes, and output file root name.

    >>> class CustomSparseGRMStep(SparseGRMStep):
    ...     def name(self):
    ...         return 'my_sparse_grm'
    ...
    ...     def attributes(self):
    ...         return {'my_attribute': '1'}
    ...
    ...     def output_root(self, temp_dir: str, checkpoint_dir: Optional[str]) -> str:
    ...         return f'{temp_dir}/my-custom-path'
    """

    memory_chunk_gib: int = 2
    """Pass-through option for "--memoryChunk". Value is in Gi."""

    num_random_markers_for_sparse_kin: int = 200
    """Pass-through option for "--numRandomMarkerforSparseKin". Number of randomly selected markers to be used to identify
        related samples for sparse GRM."""

    relatedness_cutoff: float = 0.125
    """Pass-through option for "--relatednessCutoff". The threshold to treat two samples as unrelated if IsSparseKin is True."""  # FIXME: what is sparse kin

    is_diag_of_kin_set_as_one: bool = False
    """Pass-through option for "--isDiagofKinSetAsOne". Whether to set the diagnal elements in GRM to be 1."""

    min_maf_for_grm: float = 0.01
    """Pass-through option for "--minMAFforGRM". Minimum MAF of markers used for GRM."""

    max_missing_rate_for_grm: Optional[float] = None
    """Pass-through option for "--maxMissingRateforGRM". Maximum missing rate of markers used for GRM."""

    def name(self) -> str:
        """Name of the sparse GRM job in Hail Batch."""
        return 'sparse-grm'

    def output_root(self, temp_dir: str, checkpoint_dir: Optional[str]) -> str:
        """Destination of output files generated by the sparse GRM job in Hail Batch.

        Parameters
        ----------
        temp_dir:
            Remote temporary URL. Example: gs://my-bucket/tmp/

        checkpoint_dir:
            URL to directory to write checkpointed files to. Example: gs://my-bucket/checkpoints/
        """
        working_dir = get_output_dir(self, temp_dir, checkpoint_dir)
        return f'{working_dir}/sparse-grm'

    def attributes(self) -> Optional[Dict]:
        """Attributes to specify for the sparse GRM job in Hail Batch."""
        return None

    async def _call(self, fs: AsyncFS, b: hb.Batch, input_bfile: PlinkResourceGroup, temp_dir: str, checkpoint_dir: str) -> SaigeSparseGRMResourceGroup:
        output_prefix = self.output_root(temp_dir, checkpoint_dir)
        sparse_grm = await load_saige_sparse_grm_file(fs, b, self, output_prefix)
        if sparse_grm is not None:
            return sparse_grm

        create_sparse_grm_j = b.new_job(name=self.name(), attributes=self.attributes())

        (create_sparse_grm_j.cpu(self.cpu).storage(self.storage).image(self.image).spot(self.spot))

        sparse_grm = new_saige_sparse_grm_file(create_sparse_grm_j, self.relatedness_cutoff, self.num_random_markers_for_sparse_kin)

        optional_options = []

        if self.max_missing_rate_for_grm is not None:
            optional_options.append(f'--maxMissingRateforGRM={self.max_missing_rate_for_grm}')

        optional_options_str = '    \\\n'.join(optional_options)

        command = f'''
createSparseGRM.R \\
    --plinkFile={input_bfile} \\
    --nThreads={self.cpu} \\
    --memoryChunk={self.memory_chunk_gib} \\
    --outputPrefix={sparse_grm} \\
    --numRandomMarkerforSparseKin={self.num_random_markers_for_sparse_kin} \\
    --relatednessCutoff={self.relatedness_cutoff} \\
    --isDiagofKinSetAsOne={self.is_diag_of_kin_set_as_one} \\
    --minMAFforGRM={self.min_maf_for_grm} \\
    {optional_options_str}
'''

        create_sparse_grm_j.command(command)

        checkpoint_if_requested(sparse_grm, b, self, output_prefix)

        return sparse_grm


@dataclass
class Step1NullGlmmStep(CheckpointConfigMixin, JobConfigMixin):
    """Step for computing the null model with SAIGE Step 1.

    Configures a Hail Batch job to run the SAIGE binary ``step1_fitNULLGLMM.R``.

    This class is used as an input to SaigeConfig in order to specify
    how the Null GLMM step is executed in SAIGE.

    Examples
    --------

    Use 16 cores when running the step 1 null GLMM step:

    >>> null_glmm_step = Step1NullGlmmStep(cpu=16)

    Set the relatedness cutoff to 0.05:

    >>> null_glmm_step = Step1NullGlmmStep(relatedness_cutoff=0.05)

    Notes
    -----

    You can also create a subclass of this class and redefine the
    job name, job attributes, and output file root name.

    >>> class CustomStep1NullGlmmStep(Step1NullGlmmStep):
    ...     def name(self, phenotype: Phenotype):
    ...         return f'my_null_glmm-{phenotype.name}'
    ...
    ...     def attributes(self, analysis_type: SaigeAnalysisType, phenotype: Phenotype):
    ...         return {'my_attribute': '1', 'phenotype': phenotype.name, 'analysis_type': analysis_type.name}
    ...
    ...     def output_root(self, output_dir: str, phenotype: Phenotype) -> str:
    ...         return f'{output_dir}/my-custom-path/{phenotype.name}'
    """

    inv_normalize: Optional[bool] = False
    """Pass-through argument for "--invNormalize". Only for quantitative. Whether to perform the inverse normalization for the phenotype"""

    tol: Optional[float] = 0.02
    """Pass-through argument for "--tol". Tolerance for fitting the null GLMM to converge."""

    max_iter: Optional[int] = 20
    """Pass-through argument for "--maxiter". Maximum number of iterations used to fit the null GLMM."""

    tol_pcg: Optional[float] = 1E-5
    """Pass-through argument for "--tolPCG". Tolerance for PCG to converge."""

    max_iter_pcg: Optional[int] = 500
    """Pass-through argument for "--maxiterPCG". Maximum number of iterations for PCG."""

    spa_cutoff: Optional[float] = 2
    """Pass-through argument for "--SPAcutoff". Cutoff for the deviation of score test statistics from mean in the unit of sd to perform SPA."""

    num_random_markers_for_variance_ratio: Optional[int] = 30
    """Pass-through argument for "--numRandomMarkerforVarianceRatio". An integer greater than 0. Number of markers to be randomly selected for 
    estimating the variance ratio. The number will be automatically added by 10 until the coefficient of variantion (CV) for the variance ratio 
    estimate is below ratioCVcutoff"""

    skip_model_fitting: Optional[bool] = False
    """Pass-through argument for "--skipModelFitting". Whether to skip model fitting and only to estimate the variance ratio."""  # FIXME: If TRUE, the file outputPrefix.rda is required

    skip_variance_ratio_estimation: Optional[bool] = False
    """Pass-through argument for "--skipVarianceRatioEstimation". Whether to skip model fitting and only to estimate the variance ratio."""  # FIXME: documentation is wrong. If TRUE, the file outputPrefix.rda is required

    memory_chunk_gib: Optional[int] = 2
    """Pass-through argument for "--memoryChunk". Value is in Gi."""

    tau_init: Optional[List[float]] = field(default_factory=lambda: [0, 0])
    """Pass-through argument for "--tauInit". Initial values for tau."""

    loco: Optional[bool] = True
    """Pass-through argument for "--LOCO". Whether to apply the leave-one-chromosome-out (LOCO) approach when fitting the null model using the full GRM."""

    is_low_mem_loco: Optional[bool] = False
    """Pass-through argument for "--isLowMemLOCO". Whether to output the model file by chromosome when "--LOCO=TRUE". If True, the memory usage will be lower."""

    trace_cv_cutoff: Optional[float] = 0.0025
    """Pass-through argument for "--traceCVcutoff". Threshold for coefficient of variation (CV) for the trace estimator. Number of runs for trace estimation will be increased until the CV is below the threshold."""

    n_run: Optional[int] = 30
    """Pass-through argument for "--nrun". Number of runs in trace estimation."""

    ratio_cv_cutoff: Optional[float] = 0.001
    """Pass-through argument for "--ratioCVcutoff". Threshold for coefficient of variation (CV) for estimating the variance ratio. The number of randomly selected markers will be increased until the CV is below the threshold"""

    is_cate_variance_ratio: Optional[bool] = False
    """Pass-through argument for "--isCateVarianceRatio". Whether to estimate variance ratio based on different MAC categories. If yes, variance ratio will be estimated for multiple MAC categories corresponding to cateVarRatioMinMACVecExclude and cateVarRatioMaxMACVecInclude. Currently, if isCateVarianceRatio=TRUE, then LOCO=FALSE"""

    relatedness_cutoff: Optional[float] = 0
    """Pass-through argument for "--relatednessCutoff". Threshold (minimum relatedness coefficient) to treat two samples as unrelated when the sparse GRM is used."""

    cate_var_ratio_min_mac_vec_exclude: Optional[List[float]] = field(default_factory=lambda: [10, 20.5])
    """Pass-through argument for "--cateVarRatioMinMACVecExclude". Lower bound for MAC categories. The length equals to the number of MAC categories for variance ratio estimation."""

    cate_var_ratio_min_mac_vec_include: Optional[List[float]] = field(default_factory=lambda: [20.5])
    """Pass-through argument for "--cateVarRatioMinMACVecInclude". Higher bound for MAC categories. The length equals to the number of MAC categories for variance ratio estimation minus 1."""

    is_covariate_transform: Optional[bool] = True
    """Pass-through argument for "--isCovariateTransform". Whether use qr transformation on covariates."""

    is_diag_of_kin_set_as_one: Optional[bool] = False
    """Pass-through argument for "--isDiagofKinSetAsOne". Whether to set the diagnal elements in GRM to be 1."""

    use_sparse_grm_to_fit_null: Optional[bool] = False
    """Pass-through argument for "--useSparseGRMtoFitNULL". Whether to use sparse GRM to fit the null model."""

    use_sparse_grm_for_var_ratio: Optional[bool] = False
    """Pass-through argument for "--useSparseGRMforVarRatio". Whether to use sparse GRM to estimate the variance Ratios. If TRUE, the variance ratios will be estimated using the full GRM (numerator) and the sparse GRM (denominator)."""

    min_maf_for_grm: Optional[float] = None
    """Pass-through argument for "--minMAFforGRM". Minimum MAF of markers used for GRM."""

    max_missing_rate_for_grm: Optional[float] = None
    """Pass-through argument for "--maxMissingRateforGRM". Maximum missing rate of markers used for GRM."""

    min_covariate_count: Optional[int] = None
    """Pass-through argument for "--minCovariateCount". Binary covariates with a count less than minCovariateCount will be excluded from the model to avoid convergence issues."""

    include_non_autosomal_markers_for_var_ratio: Optional[bool] = False
    """Pass-through argument for "--includeNonautoMarkersforVarRatio". Whether to allow for non-autosomal markers for variance ratio."""

    female_only: Optional[bool] = None
    """Pass-through argument for "--FemaleOnly". Whether to run null model for females only"""

    male_only: Optional[bool] = None
    """Pass-through argument for "--MaleOnly". Whether to run null model for males only."""

    is_covariate_offset: Optional[bool] = True
    """Pass-through argument for "--isCovariateOffset". Whether to estimate fixed effect coefficients."""

    def output_root(self, output_dir: str, phenotype: Phenotype) -> str:
        """Prefix of output files generated by the null model job in Hail Batch.

        Parameters
        ----------
        output_dir:
            Output directory to write to. Example: gs://my-bucket/checkpoints/
        """
        return f'{output_dir}/null-model-{phenotype.name}'

    def name(self, phenotype: Phenotype) -> str:
        """Name of the null model job in Hail Batch.

        Parameters
        ----------
        phenotype:
            The phenotype being analyzed in this SAIGE job.
        """
        return f'null-model-{phenotype.name}'

    def attributes(self, analysis_type: SaigeAnalysisType, phenotype: Phenotype) -> Optional[Dict]:
        """Attributes to specify for the null model job in Hail Batch.

        Parameters
        ----------
        analysis_type:
            Analysis type for this null model job.
        phenotype:
            The phenotype being analyzed in this null model SAIGE job.
        """
        return {'analysis_type': analysis_type.value, 'trait_type': phenotype.phenotype_type.value}

    async def _call(
        self,
        fs: AsyncFS,
        b: hb.Batch,
        *,
        input_bfile: PlinkResourceGroup,
        input_phenotypes: TextResourceFile,
        keep_samples_list: Optional[TextResourceFile],
        phenotype: Phenotype,
        analysis_type: SaigeAnalysisType,
        phenotype_config: PhenotypeConfig,
        sparse_grm: Optional[SaigeSparseGRMResourceGroup],
        temp_dir: str,
        checkpoint_dir: Optional[str],
    ) -> SaigeGLMMResourceGroup:
        working_dir = get_output_dir(self, temp_dir, checkpoint_dir)
        output_root = self.output_root(working_dir, phenotype)

        glmm_resource_output = await load_saige_glmm_file(fs, b, self, output_root, analysis_type)
        if glmm_resource_output:
            return glmm_resource_output

        j = (
            b.new_job(
                name=self.name(phenotype=phenotype),
                attributes=self.attributes(analysis_type, phenotype),
            )
            .storage(self.storage)
            .image(self.image)
            .cpu(self.cpu)
            .memory(self.memory)
            .spot(self.spot)
        )

        null_glmm = new_saige_glmm_file(j, analysis_type)

        command = self._command(
            input_bfile,
            input_phenotypes,
            keep_samples_list,
            phenotype_config,
            phenotype,
            null_glmm,
            sparse_grm,
        )

        j.command(command)

        checkpoint_if_requested(null_glmm, b, self, output_root)

        return null_glmm

    def _command(
        self,
        input_bfile: PlinkResourceGroup,
        phenotypes_file: TextResourceFile,
        keep_samples_list: Optional[TextResourceFile],
        phenotype_config: PhenotypeConfig,
        phenotype: Phenotype,
        null_glmm: SaigeGLMMResourceGroup,
        sparse_grm: Optional[SaigeSparseGRMResourceGroup],
    ) -> str:
        test_type = saige_phenotype_to_test_type[phenotype.phenotype_type]

        covariates = [cov.name for cov in phenotype_config.covariates]

        options = [
            f'--plinkFile={input_bfile}',
            f'--phenoFile={phenotypes_file}',
            f'--covarColList={",".join(covariates)}',
            f'--phenoCol={phenotype.name}',
            f'--sampleIDColinphenoFile={phenotype_config.sample_id_col}',
            f'--traitType={test_type.value}',
            f'--outputPrefix={null_glmm}',
            f'--outputPrefix_varRatio={null_glmm}',
            f'--nThreads={self.cpu}',
        ]

        if sparse_grm is not None:
            options.append(f'--sparseGRMFile={sparse_grm.grm}')
            options.append(f'--sparseGRMSampleIDFile={sparse_grm.sample_ids}')

        q_covariates = [cov.name for cov in phenotype_config.covariates
                        if cov.phenotype_type == SaigePhenotype.BINARY]
        if len(q_covariates) > 0:
            options.append(f'--qCovarColList={",".join(q_covariates)}')

        if keep_samples_list is not None:
            options.append(f'--SampleIDIncludeFile={keep_samples_list}')
        if self.inv_normalize is not None:
            options.append(f'--invNormalize={bool_upper_str(self.inv_normalize)}')
        if self.tol is not None:
            options.append(f'--tol={self.tol}')
        if self.max_iter is not None:
            options.append(f'--maxiter={self.max_iter}')
        if self.tol_pcg is not None:
            options.append(f'--tolPCG={self.tol_pcg}')
        if self.max_iter_pcg is not None:
            options.append(f'--maxiterPCG={self.max_iter_pcg}')
        if self.spa_cutoff is not None:
            options.append(f'--SPAcutoff={self.spa_cutoff}')
        if self.num_random_markers_for_variance_ratio is not None:
            options.append(f'--numRandomMarkerforVarianceRatio={self.num_random_markers_for_variance_ratio}')
        if self.skip_model_fitting is not None:
            options.append(f'--skipModelFitting={bool_upper_str(self.skip_model_fitting)}')
        if self.skip_variance_ratio_estimation is not None:
            options.append(f'--skipVarianceRatioEstimation={bool_upper_str(self.skip_variance_ratio_estimation)}')
        if self.memory_chunk_gib is not None:
            options.append(f'--memoryChunk={self.memory_chunk_gib}')
        if self.tau_init is not None:
            tau_init = ','.join(str(tau) for tau in self.tau_init)
            options.append(f'--tauInit={tau_init}')
        if self.loco is not None:
            options.append(f'--LOCO={bool_upper_str(self.loco)}')
        if self.is_low_mem_loco is not None:
            options.append(f'--isLowMemLOCO={bool_upper_str(self.is_low_mem_loco)}')
        if self.trace_cv_cutoff is not None:
            options.append(f'--traceCVcutoff={self.trace_cv_cutoff}')
        if self.n_run is not None:
            options.append(f'--nrun={self.n_run}')
        if self.ratio_cv_cutoff is not None:
            options.append(f'--ratioCVcutoff={self.ratio_cv_cutoff}')
        if self.is_cate_variance_ratio is not None:
            options.append(f'--isCateVarianceRatio={bool_upper_str(self.is_cate_variance_ratio)}')
        if self.relatedness_cutoff is not None:
            options.append(f'--relatednessCutoff={self.relatedness_cutoff}')
        if self.cate_var_ratio_min_mac_vec_exclude is not None:
            exclude_str = ','.join(str(item) for item in self.cate_var_ratio_min_mac_vec_exclude)
            options.append(f'--cateVarRatioMinMACVecExclude={exclude_str}')
        if self.cate_var_ratio_min_mac_vec_include is not None:
            include_str = ','.join(str(item) for item in self.cate_var_ratio_min_mac_vec_include)
            options.append(f'--cateVarRatioMinMACVecInclude={include_str}')
        if self.is_covariate_transform is not None:
            options.append(f'--isCovariateTransform={bool_upper_str(self.is_covariate_transform)}')
        if self.is_diag_of_kin_set_as_one is not None:
            options.append(f'--isDiagofKinSetAsOne={bool_upper_str(self.is_diag_of_kin_set_as_one)}')
        if self.use_sparse_grm_to_fit_null is not None:
            options.append(f'--useSparseGRMtoFitNULL={bool_upper_str(self.use_sparse_grm_to_fit_null)}')
        if self.use_sparse_grm_for_var_ratio is not None:
            options.append(f'--useSparseGRMforVarRatio={bool_upper_str(self.use_sparse_grm_for_var_ratio)}')
        if self.min_maf_for_grm is not None:
            options.append(f'--minMAFforGRM={self.min_maf_for_grm}')
        if self.max_missing_rate_for_grm is not None:
            options.append(f'--maxMissingRateforGRM={self.max_missing_rate_for_grm}')
        if self.min_covariate_count is not None:
            options.append(f'--minCovariateCount={self.min_covariate_count}')
        if self.include_non_autosomal_markers_for_var_ratio is not None:
            options.append(f'--includeNonautoMarkersforVarRatio={bool_upper_str(self.include_non_autosomal_markers_for_var_ratio)}')
        if self.female_only is not None:
            if phenotype_config.sex_col is None:
                raise ValueError('Cannot specify female only. No sex column specified.')
            if phenotype_config.female_code is None:
                raise ValueError('Cannot specify female only. No code specified for females.')
            options.append(f'--FemaleOnly={bool_upper_str(self.female_only)}')
            options.append(f'--sexCol={phenotype_config.sex_col}')
            options.append(f'--FemaleCode={phenotype_config.female_code}')
        if self.male_only is not None:
            if phenotype_config.sex_col is None:
                raise ValueError('Cannot specify male only. No sex column specified.')
            if phenotype_config.male_code is None:
                raise ValueError('Cannot specify male only. No code specified for males.')
            options.append(f'--MaleOnly={bool_upper_str(self.male_only)}')
            options.append(f'--sexCol={phenotype_config.sex_col}')
            options.append(f'--MaleCode={phenotype_config.male_code}')
        if self.is_covariate_offset is not None:
            options.append(f'--isCovariateOffset={bool_upper_str(self.is_covariate_offset)}')

        options_str = '  \\\n'.join(options)

        command = f'''
set -o pipefail;

perl -pi -e s/^chr// {input_bfile.bim};

step1_fitNULLGLMM.R \\
    {options_str}
'''
        return command


@dataclass
class Step2SPAStep(CheckpointConfigMixin, JobConfigMixin):
    """Step for running SAIGE Step 2 Saddle Point Approximation.

    Configures a Hail Batch job to run the SAIGE binary ``step2_SPAtests.R``.

    This class is used as an input to SaigeConfig in order to specify
    how the saddle point approximation step is executed in SAIGE.

    Examples
    --------

    Use 16 cores when running the step 2 SPA step:

    >>> spa_step = Step2SPAStep(cpu=16)

    Set the relatedness cutoff to 0.05:

    >>> spa_step = Step2SPAStep(relatedness_cutoff=0.05)

    Notes
    -----

    You can also create a subclass of this class and redefine the
    job name, job attributes, and output file root name.

    >>> class CustomStep2SPAStep(Step2SPAStep):  # FIXME
    ...     def name(self, phenotype: Phenotype, chunk: VariantChunk) -> str:
    ...         return f'step2-spa-{phenotype.name}-{chunk.idx}'
    """

    is_imputed: Optional[bool] = False
    """Pass-through argument for "--is_imputed_data". Whether the dosages/genotypes imputed 
    are imputed. If True, the program will output the imputed info score."""

    min_maf: Optional[float] = 0.0
    """Pass-through argument for "--minMAF". Minimum minor allele frequency for markers to be 
    tested. The higher threshold between minMAC and minMAF will be used."""

    min_mac: Optional[int] = 5
    """Pass-through argument for "--minMAC". Minimum minor allele count for markers to be tested. 
    The higher threshold between minMAC and minMAF will be used."""

    min_group_mac_in_burden_test: Optional[int] = 5
    """Pass-through argument for "--minGroupMAC_in_BurdenTest". Only applied when only Burden 
    tests are performed (r.corr=1). Minimum minor allele count in the Burden test for the 
    pseudo marker."""

    min_info: Optional[float] = 0.0
    """Pass-through argument for "--minInfo". Minimum Info for markers to be tested if 
    is_imputed_data=True."""

    max_missing: Optional[float] = 0.15
    """Pass-through argument for "--maxMissing". Maximum missing rate for markers 
    to be tested."""

    impute_method: Optional[str] = 'minor'
    """Pass-through argument for "--impute_method". Imputation method for missing dosages.
     best_guess, mean or minor. best_guess: missing dosages imputed as best guessed genotyes 
     round(2*allele frequency). mean: missing dosages are imputed as mean (2*allele frequency). 
     minor: missing dosages are imputed as minor allele homozygotes."""

    loco: Optional[bool] = False  # FIXME: do we want this?
    """Pass-through argument for "--LOCO". Whether to apply the leave-one-chromosome-out option. 
    If TRUE, --chrom is required."""

    chrom: Optional[str] = None
    """Pass-through argument for "--chrom". If `loco` is specified, `chrom` is required. Also required 
    for VCF/BCF/SAV input."""

    markers_per_chunk: Optional[int] = 10000
    """Pass-through argument for "--markers_per_chunk". Number of markers to be tested 
    and output in each chunk in the single-variant assoc tests."""

    groups_per_chunk: Optional[int] = 100
    """Pass-through argument for "--groups_per_chunk". Number of groups/sets to be read in 
    and tested in each chunk in the set-based assoc tests."""

    output_more_details: Optional[bool] = False
    """Pass-through argument for "--is_output_moreDetails". Whether to output heterozygous 
    and homozygous counts in cases and controls. By default, FALSE. If True, the columns 
    homN_Allele2_cases, hetN_Allelelogical2_cases, homN_Allele2_ctrls, hetN_Allele2_ctrls 
    will be output."""

    max_maf_in_group_test: Optional[List[float]] = field(default_factory=lambda: [0.0001, 0.001, 0.01])
    """Pass-through argument for "--maxMAF_in_groupTest". Max MAF for markers tested in 
    group test."""

    max_mac_in_group_test: Optional[List[int]] = field(default_factory=lambda: [0])
    """Pass-through argument for "--maxMAC_in_groupTest". Max MAC for markers tested 
    in group test."""

    annotation_in_group_test: Optional[str] = 'lof,missense;lof,missense;lof;synonymous'
    """Pass-through argument for "--annotation_in_groupTest". Annotations of markers to be
    tested in the set-based tests seperated by comma. using ; to combine multiple annotations
    in the same test, e.g. lof,missense;lof,missense;lof;synonymous will test lof variants 
    only, missense+lof variants, and missense+lof+synonymous variants."""

    relatedness_cutoff: Optional[float] = 0.0
    """Pass-through argument for "--relatednessCutoff". Threshold (minimum relatedness coefficient)
     to treat two samples as unrelated when the sparse GRM is used."""

    x_par_region: Optional[List[str]] = None
    """Pass-through argument for "--X_PARregion". Ranges of (pseudoautosomal) PAR region 
    on chromosome X, which are seperated by comma and in the format start:end. By default: 
    '60001-2699520,154931044-155260560' in the UCSC build hg19. For males, there are two 
    X alleles in the PAR region, so PAR regions are treated the same as autosomes. In the 
    NON-PAR regions (outside the specified PAR regions on chromosome X), for males, there 
    is only one X allele. If is_rewrite_XnonPAR_forMales=TRUE, genotypes/dosages of all 
    variants in the NON-PAR regions on chromosome X will be mutliplied by 2."""

    is_rewrite_x_nonpar_for_males: Optional[bool] = False
    """Pass-through argument for "--is_rewrite_XnonPAR_forMales". Whether to rewrite gentoypes or dosages of variants in the NON-PAR regions on chromosome X for males (multiply by 2). Note, only use is_rewrite_XnonPAR_forMales=TRUE when the specified VCF or Bgen file only has variants on chromosome X. When is_rewrite_XnonPAR_forMales=TRUE, the program does not check the chromosome value by assuming all variants are on chromosome X."""

    mac_cutoff_to_collapse_ultra_rare: Optional[int] = 10
    """Pass-through argument for "--MACCutoff_to_CollapseUltraRare". MAC cutoff to collpase the ultra rare variants (<= MACCutoff_to_CollapseUltraRare) in the set-based association tests."""

    cate_var_ratio_min_mac_vec_exclude: Optional[List[float]] = field(default_factory=lambda: [10, 20.5])
    """Pass-through argument for "--cateVarRatioMinMACVecExclude". Lower bound for MAC categories. The length equals to the number of MAC categories for variance ratio estimation."""

    cate_var_ratio_max_mac_vec_include: Optional[List[float]] = field(default_factory=lambda: [20.5])
    """Pass-through argument for "--cateVarRatioMaxMACVecInclude". Higher bound for MAC categories. The length equals to the number of MAC categories for variance ratio estimation minus 1."""

    weights_beta: Optional[List[float]] = field(default_factory=lambda: [1, 25])
    """Pass-through argument for "--weights.beta". Parameters for the beta distribution to weight genetic markers in gene-based tests."""

    r_corr: Optional[float] = 0.0
    """Pass-through argument for "--r.corr". If r.corr = 1, only Burden tests will be performed. If r.corr = 0, SKAT-O tests will be performed and results for Burden tests and SKAT tests will be output too."""

    markers_per_chunk_in_group_test: Optional[int] = 100
    """Pass-through argument for "--markers_per_chunk_in_groupTest". Number of markers in each chunk when calculating the variance covariance matrix in the set/group-based tests."""

    condition: Optional[List[str]] = None
    """Pass-through argument for "--condition". For conditional analysis. Variant ids are in the format ``chr:pos_ref/alt`` and seperated by by comma. e.g. ``chr:3101651171_C/T``, ``chr:3101651186_G/A``."""

    weights_for_condition: Optional[List[float]] = None
    """Pass-through argument for "--weights_for_condition". weights for conditioning markers for gene- or region-based tests. The length equals to the number of conditioning markers, delimited by comma. e.g. '1,2,3. If not specified, the default weights will be generated based on beta(MAF, 1, 25). Use `weights_beta` to change the parameters for the Beta distribution."""

    spa_cutoff: Optional[float] = 2.0
    """Pass-through argument for "--SPAcutoff". If the test statistic lies within the standard deviation cutoff of the mean, p-value based on traditional score test is returned."""

    dosage_zerod_cutoff: Optional[float] = 0.2
    """Pass-through argument for "--dosage_zerod_cutoff". If `is_imputed_data` = True, for variants with MAC <= dosage_zerod_MAC_cutoff, dosages <= dosageZerodCutoff with be set to 0."""

    dosage_zerod_mac_cutoff: Optional[int] = 10
    """Pass-through argument for "--dosage_zerod_MAC_cutoff". If `is_imputed_data` = True, For variants with MAC <= dosage_zerod_MAC_cutoff, dosages <= dosageZerodCutoff with be set to 0."""

    is_single_in_group_test: Optional[bool] = True
    """Pass-through argument for "--is_single_in_groupTest". Whether to output single-variant assoc test results when perform group tests. Note, single-variant assoc test results will always be output when SKAT and SKAT-O tests are conducted with --r.corr=0. This parameter should only be used when only Burden tests are condcuted with --r.corr=1."""

    is_no_weight_in_group_test: Optional[bool] = False
    """Pass-through argument for "--is_no_weight_in_groupTest". Whether no weights are used in group test. If False, weights will be calculated based on MAF from the Beta distribution with parameters `weights_beta` or weights will be extracted from the group file if available"""

    is_output_marker_list_in_group_test: Optional[bool] = True
    """Pass-through argument for "--is_output_markerList_in_groupTest". Whether to output the marker lists included in the set-based tests for each mask."""

    is_firth_beta: Optional[bool] = False
    """Pass-through argument for "--is_Firth_beta". Whether to estimate effect sizes using approx Firth, only for binary traits."""

    p_cutoff_for_firth: Optional[float] = 0.01
    """Pass-through argument for "--pCutoffforFirth". p-value cutoff to use approx Firth to estiamte the effect sizes. Only for binary traits. The effect sizes of markers with p-value <= pCutoffforFirth will be estimated using approx Firth."""

    is_fast_test: Optional[bool] = None
    """Pass-through argument for "--is_fastTest". Whether to use the fast mode for tests."""

    max_mac_for_er: Optional[int] = 4
    """Pass-through argument for "--max_MAC_for_ER". p-values of genetic variants with MAC <= max_MAC_for_ER will be calculated via efficient resampling."""

    specify_males: Optional[bool] = False
    """If True, specify a list of male samples using the flag "--sampleFile_male". The PhenotypeConfig must have the sex column specified along with the code for males."""

    mkl_off: bool = False
    """Turn off MKL."""

    def name(self, phenotype: Phenotype, chunk: VariantChunk) -> str:
        return f'step2-spa-{phenotype.name}-{chunk.idx}'

    def attributes(
        self, *, analysis_type: SaigeAnalysisType, phenotype: Phenotype, chunk: VariantChunk
    ) -> Optional[Dict]:
        return {
            'analysis_type': analysis_type.value,
            'trait_type': phenotype.phenotype_type.value,
            'phenotype': phenotype.name,
            'chunk': chunk.name,
        }

    def output_file_prefix(
        self, temp_dir: str, checkpoint_dir: Optional[str], phenotype_name: str, chunk: VariantChunk
    ) -> str:
        working_dir = get_output_dir(self, temp_dir, checkpoint_dir)
        return f'{working_dir}/results/{phenotype_name}/{chunk.idx}'

    def output_glob(self, temp_dir: str, checkpoint_dir: Optional[str], phenotype_name: str) -> str:
        working_dir = get_output_dir(self, temp_dir, checkpoint_dir)
        return f'{working_dir}/results/{phenotype_name}/*'

    def _command(
        self,
        *,
        mt_path: str,
        analysis_type: SaigeAnalysisType,
        null_model: Union[SaigeGeneGLMMResourceGroup, SaigeGLMMResourceGroup],
        input_data_type: SaigeInputDataType,
        chunk: VariantChunk,
        result: SaigeResultResourceGroup,
        sparse_grm: Optional[SaigeSparseGRMResourceGroup],
        group_annotations: Optional[TextResourceFile],
        phenotype_config: PhenotypeConfig,
    ):
        if self.mkl_off:
            mkl_off = 'export MKL_NUM_THREADS=1; export MKL_DYNAMIC=false; export OMP_NUM_THREADS=1; export OMP_DYNAMIC=false; '
        else:
            mkl_off = ''

        if input_data_type == SaigeInputDataType.VCF:
            export_cmd = f'hl.export_vcf(mt.select_entries("GT"), "/data.vcf.bgz")'
            input_flags = [
                f'--vcfFile=/data.vcf.bgz',
                f'--vcfFileIndex=/data.vcf.bgz.csi',
                f'--vcfField=GT',
            ]
            index_cmd = 'tabix -C /data.vcf.bgz'
        else:
            export_cmd = f'hl.export_bgen(mt, "/data")'
            input_flags = [
                f'--bgenFile=/data.bgen',
                f'--bgenFileIndex=/data.bgen.idx',
                f'--sampleFile=/data.sample',
            ]
            index_cmd = ''

        if analysis_type == SaigeAnalysisType.GENE:
            assert sparse_grm is not None and group_annotations is not None
            assert chunk.groups is not None
            group_ann_filter_cmd = f'''
cat > filter_gene_annotations.py <<EOF
import hail as hl
import json
annotations = hl.import_table("{group_annotations}")
groups = json.loads("{json.dumps(chunk.groups)}")
annotations = annotations.filter(hl.is_defined(groups[annotations.group]))  # fixme: what is the right field name here?
EOF
'''
        else:
            group_ann_filter_cmd = ''

        hail_io_cmd = f'''
cat > read_from_mt.py <<EOF
import hail as hl
mt = hl.read_matrix_table("{mt_path}")
interval = hl.parse_locus_interval("{chunk.to_interval_str()}", reference_genome=mt.locus.dtype.reference_genome)
mt = mt.filter_rows(interval.contains(mt.locus))
{export_cmd}
EOF
python3 read_from_mt.py
{index_cmd}
'''

        saige_options = [
            f'--chrom={chunk.interval.start.contig}',
            f'--GMMATmodelFile={null_model.rda}',
            f'--varianceRatioFile={null_model.variance_ratio}',
            f'--SAIGEOutputFile={result}',
        ]

        if self.min_maf is not None:
            saige_options.append(f'--minMAF={self.min_maf}')
        if self.min_mac is not None:
            saige_options.append(f'--minMAC={self.min_mac}')
        if self.min_group_mac_in_burden_test is not None:
            saige_options.append(f'--minGroupMAC_in_BurdenTest={self.min_group_mac_in_burden_test}')
        if self.min_info is not None:
            saige_options.append(f'--minInfo={self.min_info}')
        if self.max_missing is not None:
            saige_options.append(f'--maxMissing={self.max_missing}')
        if self.impute_method is not None:
            saige_options.append(f'--impute_method={self.impute_method}')
        if self.loco is not None:
            saige_options.append(f'--LOCO={bool_upper_str(self.loco)}')
        if self.chrom is not None:
            saige_options.append(f'--chrom={self.chrom}')
        if self.markers_per_chunk is not None:
            saige_options.append(f'--markers_per_chunk={self.markers_per_chunk}')
        if self.groups_per_chunk is not None:
            saige_options.append(f'--groups_per_chunk={self.groups_per_chunk}')
        if self.output_more_details is not None:
            saige_options.append(f'--is_output_moreDetails={bool_upper_str(self.output_more_details)}')
        if self.max_maf_in_group_test is not None:
            mafs = ','.join(str(maf) for maf in self.max_maf_in_group_test)
            saige_options.append(f'--maxMAF_in_groupTest={mafs}')
        if self.max_mac_in_group_test is not None:
            macs = ','.join(str(mac) for mac in self.max_mac_in_group_test)
            saige_options.append(f'--maxMAC_in_groupTest={macs}')
        if self.annotation_in_group_test is not None:
            saige_options.append(f'--annotation_in_groupTest={self.annotation_in_group_test}')
        if self.relatedness_cutoff is not None:
            saige_options.append(f'--relatednessCutoff={self.relatedness_cutoff}')
        if self.x_par_region is not None:
            par_regions = ','.join(self.x_par_region)
            saige_options.append(f'--X_PARregion={par_regions}')
        if self.is_rewrite_x_nonpar_for_males is not None:
            saige_options.append(f'--is_rewrite_XnonPAR_forMales={bool_upper_str(self.is_rewrite_x_nonpar_for_males)}')
        if self.mac_cutoff_to_collapse_ultra_rare is not None:
            saige_options.append(f'--MACCutoff_to_CollapseUltraRare={self.mac_cutoff_to_collapse_ultra_rare}')
        if self.cate_var_ratio_min_mac_vec_exclude is not None:
            min_mac_vec = ','.join(str(mac) for mac in self.cate_var_ratio_min_mac_vec_exclude)
            saige_options.append(f'--cateVarRatioMinMACVecExclude={min_mac_vec}')
        if self.cate_var_ratio_max_mac_vec_include is not None:
            max_mac_vec = ','.join(str(mac) for mac in self.cate_var_ratio_max_mac_vec_include)
            saige_options.append(f'--cateVarRatioMaxMACVecInclude={max_mac_vec}')
        if self.weights_beta is not None:
            weights = ','.join(str(wt) for wt in self.weights_beta)
            saige_options.append(f'--weights.beta={weights}')
        if self.r_corr is not None:
            saige_options.append(f'--r.corr={self.r_corr}')
        if self.markers_per_chunk_in_group_test is not None:
            saige_options.append(f'--markers_per_chunk_in_groupTest={self.markers_per_chunk_in_group_test}')
        if self.condition is not None:
            condition = ','.join(self.condition)
            saige_options.append(f'--condition={condition}')
        if self.weights_for_condition is not None:
            weights = ','.join(str(wt) for wt in self.weights_for_condition)
            saige_options.append(f'--weights_for_condition={weights}')
        if self.spa_cutoff is not None:
            saige_options.append(f'--SPAcutoff={self.spa_cutoff}')
        if self.dosage_zerod_cutoff is not None:
            saige_options.append(f'--dosage_zerod_cutoff={self.dosage_zerod_cutoff}')
        if self.dosage_zerod_mac_cutoff is not None:
            saige_options.append(f'--dosage_zerod_MAC_cutoff={self.dosage_zerod_mac_cutoff}')
        if self.is_no_weight_in_group_test is not None:
            saige_options.append(f'--is_no_weight_in_groupTest={bool_upper_str(self.is_no_weight_in_group_test)}')
        if self.is_output_marker_list_in_group_test is not None:
            saige_options.append(f'--is_output_markerList_in_groupTest={bool_upper_str(self.is_output_marker_list_in_group_test)}')
        if self.is_firth_beta is not None:
            saige_options.append(f'--is_Firth_beta={bool_upper_str(self.is_firth_beta)}')
        if self.p_cutoff_for_firth is not None:
            saige_options.append(f'--pCutoffforFirth={self.p_cutoff_for_firth}')
        if self.is_fast_test is not None:
            saige_options.append(f'--is_fastTest={bool_upper_str(self.is_fast_test)}')
        if self.max_mac_for_er is not None:
            saige_options.append(f'--max_MAC_for_ER={self.max_mac_for_er}')
        if self.specify_males:
            if phenotype_config.sex_col is None or phenotype_config.male_code is None:
                raise ValueError(
                    'cannot specify males for analyses without setting the sex column and male code in the PhenotypeConfig.'
                )
            saige_options.append(f'--sampleFile_male=/males')
            create_males_file = f'''
cat > filter_males.py <<EOF
import hail as hl
ht = hl.import_table("{phenotype_config.phenotypes_file}")
ht = ht.key_by("{phenotype_config.sample_id_col}")
ht = ht.filter(ht["{phenotype_config.sex_col}"] == "{phenotype_config.male_code}")
ht.select().export('/males', header=False)
EOF
'''
        else:
            create_males_file = ''

        if analysis_type == SaigeAnalysisType.GENE:
            gene_options = [
                f'--groupFile={group_annotations}',
                f'--sparseGRMFile={sparse_grm.grm}',
                f'--sparseGRMSampleIDFile={sparse_grm.sample_ids}'
            ]
            if self.is_single_in_group_test is not None:
                gene_options.append(f'--is_single_in_groupTest={bool_upper_str(self.is_single_in_group_test)}')
        else:
            gene_options = []

        input_flags = '    \\\n'.join(input_flags)
        saige_options = '    \\\n'.join(saige_options)
        gene_options = '    \\\n'.join(gene_options)

        command = f'''
set -o pipefail;
{mkl_off}

{hail_io_cmd}
{group_ann_filter_cmd}
{create_males_file}

step2_SPAtests.R \\
{input_flags} \\
{saige_options} \\
{gene_options}
'''

        return command

    async def _call(
        self,
        fs: AsyncFS,
        b: hb.Batch,
        *,
        mt_path: str,
        temp_dir: str,
        checkpoint_dir: Optional[str],
        analysis_type: SaigeAnalysisType,
        null_model: Union[SaigeGeneGLMMResourceGroup, SaigeGLMMResourceGroup],
        input_data_type: SaigeInputDataType,
        chunk: VariantChunk,
        phenotype: Phenotype,
        phenotype_config: PhenotypeConfig,
        sparse_grm: Optional[SaigeSparseGRMResourceGroup] = None,
        group_annotations: Optional[TextResourceFile] = None,
    ) -> Union[SaigeGeneResultResourceGroup, SaigeResultResourceGroup]:
        output_root = self.output_file_prefix(temp_dir, checkpoint_dir, phenotype.name, chunk)

        results = await load_saige_result_file(fs, b, self, output_root, analysis_type)
        if results is not None:
            return results

        j = (
            b.new_job(
                name=self.name(phenotype=phenotype, chunk=chunk),
                attributes=self.attributes(
                    phenotype=phenotype,
                    chunk=chunk,
                    analysis_type=analysis_type,
                ),
            )
            .storage(self.storage)
            .image(self.image)
            .cpu(self.cpu)
            .memory(self.memory)
            .spot(self.spot)
        )

        results = new_saige_result_file(j, analysis_type)

        command = self._command(
            mt_path=mt_path,
            analysis_type=analysis_type,
            null_model=null_model,
            input_data_type=input_data_type,
            chunk=chunk,
            result=results,
            sparse_grm=sparse_grm,
            group_annotations=group_annotations,
            phenotype_config=phenotype_config,
        )

        j.command(command)

        b.write_output(results, output_root)

        return results


@dataclass
class CompilePhenotypeResultsStep(CheckpointConfigMixin, JobConfigMixin):
    """Step for compiling the results for a single phenotype."""

    def name(self, phenotype: Phenotype) -> str:
        return f'compile-results-{phenotype.name}'

    def attributes(self, *, phenotype: Phenotype) -> Optional[Dict]:
        return {'phenotype': phenotype.name}

    def results_path_glob(self, temp_dir: str, checkpoint_dir: Optional[str]):
        working_dir = get_output_dir(self, temp_dir, checkpoint_dir)
        return f'{working_dir}/compiled-results/*.tsv'

    def output_file(self, temp_dir: str, checkpoint_dir: Optional[str], phenotype_name: str) -> str:
        working_dir = get_output_dir(self, temp_dir, checkpoint_dir)
        return f'{working_dir}/compiled-results/{phenotype_name}.tsv'  # FIXME: compress this

    async def check_if_output_exists(self,
                                     fs: AsyncFS,
                                     b: hb.Batch,
                                     phenotype: Phenotype,
                                     temp_dir: str,
                                     checkpoint_dir: Optional[str]) -> Optional[TextResourceFile]:
        output_file = self.output_file(temp_dir, checkpoint_dir, phenotype.name)
        return await load_text_file(fs, b, self, output_file)

    def _command(self, results_path: str, phenotype_name: str, output_file: str) -> str:
        return f'''
cat > compile_results.py <<EOF
import hail as hl
ht = hl.import_table("{results_path}", impute=True)
ht = ht.annotate(phenotype="{phenotype_name}")
ht.export("{output_file}")
EOF
python3 compile_results.py
'''

    async def _call(
        self,
        fs: AsyncFS,
        b: hb.Batch,
        phenotype: Phenotype,
        results_path: str,
        dependencies: List[hb.Job],
        temp_dir: str,
        checkpoint_dir: Optional[str],
    ) -> TextResourceFile:
        output_file = self.output_file(temp_dir, checkpoint_dir, phenotype.name)
        results = await load_text_file(fs, b, self, output_file)
        if results is not None:
            return results

        j = (b
             .new_job(name=self.name(phenotype), attributes=self.attributes(phenotype=phenotype))
             .image(self.image)
             .cpu(self.cpu)
             .memory(self.memory)
             .depends_on(*dependencies)
        )

        compiled_results = new_text_file(j)

        cmd = self._command(results_path, phenotype.name, compiled_results)

        j.command(cmd)

        b.write_output(compiled_results, output_file)

        return compiled_results


@dataclass
class CompileAllResultsStep(CheckpointConfigMixin, JobConfigMixin):
    """Step for compiling the results across multiple phenotypes into a Hail Table."""

    overwrite: bool = True
    """Overwrite any existing files at the output path."""

    def name(self) -> str:
        return 'compile-all-results'

    def _command(self, mt_path: str, results_path: str, results_ht: HailTableResourceFile) -> str:
        return f'''
cat > compile_results.py <<EOF
import hail as hl
mt = hl.read_matrix_table("{mt_path}")
reference_genome=mt.locus.dtype.reference_genome
ht = hl.import_table("{results_path}", impute=True)
ht = ht.annotate(locus=hl.locus(hl.str(ht.CHR), ht.POS, reference_genome=reference_genome), alleles=hl.array([ht.Allele1, ht.Allele2]))
ht = ht.key_by(ht.locus, ht.alleles, ht.phenotype)
ht = ht.drop('CHR', 'POS', 'Allele1', 'Allele2')
ht.write("{results_ht}")
EOF
python3 compile_results.py
'''

    async def _call(
        self,
        fs: AsyncFS,
        b: hb.Batch,
        results_path: str,
        output_ht_path: str,
        dependencies: List[hb.Job],
        mt_path: str,
    ):
        if fs.isdir(output_ht_path) and not self.overwrite:
            return

        j = (b
             .new_job(name=self.name())
             .image(self.image)
             .cpu(self.cpu)
             .memory(self.memory)
             .depends_on(*dependencies)
        )

        results_ht = new_hail_table(j)

        cmd = self._command(mt_path, results_path, results_ht)

        j.command(cmd)

        b.write_output(results_ht, output_ht_path)
